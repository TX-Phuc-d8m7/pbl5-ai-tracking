{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc8225f7-411e-4183-9a10-d933eccadd85",
   "metadata": {},
   "source": [
    "# GENERATE DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d211445",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e592cc6f-3721-45a7-990f-84cdd88b4d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Generate dataset\n",
    "#2. Train the classifier and save it\n",
    "#3. Detect the face and named it if it is already stored in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc19e032-5f72-4aba-a85a-71466f665717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1346163-f390-486b-a3c8-16751ab76d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting samples completed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def generate_dataset():\n",
    "    # Load Haar cascades\n",
    "    face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    profile_classifier = cv2.CascadeClassifier(\"haarcascade_profileface.xml\")\n",
    "\n",
    "    def face_cropped(img):\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # 1. Detect frontal faces\n",
    "        faces = face_classifier.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=4,\n",
    "            minSize=(50, 50)\n",
    "        )\n",
    "        if len(faces) > 0:\n",
    "            # Detected frontal\n",
    "            return faces[0], False\n",
    "\n",
    "        # 2. Detect right-profile faces\n",
    "        faces = profile_classifier.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=4,\n",
    "            minSize=(50, 50)\n",
    "        )\n",
    "        if len(faces) > 0:\n",
    "            return faces[0], False\n",
    "\n",
    "        # 3. Detect left-profile faces by flipping image\n",
    "        flipped_gray = cv2.flip(gray, 1)\n",
    "        faces = profile_classifier.detectMultiScale(\n",
    "            flipped_gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=4,\n",
    "            minSize=(50, 50)\n",
    "        )\n",
    "        if len(faces) > 0:\n",
    "            # Get the first detected\n",
    "            x, y, w, h = faces[0]\n",
    "            # Convert x back to original image coordinates\n",
    "            x = gray.shape[1] - x - w\n",
    "            return (x, y, w, h), True\n",
    "\n",
    "        # No face detected\n",
    "        return None, False\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    user_id = 2  # Change as needed\n",
    "    img_id = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        result, flipped = face_cropped(frame)\n",
    "        if result is not None:\n",
    "            x, y, w, h = result\n",
    "            crop = frame[y:y+h, x:x+w]\n",
    "            # Resize but keep the RGB colors\n",
    "            face_resized = cv2.resize(crop, (300, 300))\n",
    "            \n",
    "            img_id += 1\n",
    "            filename = f\"data/kimly.{user_id}.{img_id}.jpg\"\n",
    "            cv2.imwrite(filename, face_resized)  # Save the color image directly\n",
    "\n",
    "            # Annotate detection type\n",
    "            label = f\"{img_id} - {'L' if flipped else 'F'}\"\n",
    "            cv2.putText(\n",
    "                face_resized, label, (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2\n",
    "            )\n",
    "            cv2.imshow(\"Cropped face\", face_resized)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27 or img_id >= 150:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Collecting samples completed.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    generate_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7462f18-26c7-48b7-a5b6-901655b08e75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (11.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pillow\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cb9d1b8-064a-4f42-9cee-ac100dd9cef9",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'data\\\\an'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m     clf\u001b[38;5;241m.\u001b[39mtrain(faces,ids)\n\u001b[0;32m     25\u001b[0m     clf\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier.xml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m \u001b[43mtrain_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m, in \u001b[0;36mtrain_classifier\u001b[1;34m(data_dir)\u001b[0m\n\u001b[0;32m     10\u001b[0m ids \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m path:\n\u001b[1;32m---> 13\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m     imageNp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplit(image)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:3465\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3462\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fp)\n\u001b[0;32m   3464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3465\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3466\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3467\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'data\\\\an'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image #pip install pillow\n",
    "import numpy as np    # pip install numpy\n",
    " \n",
    "def train_classifier(data_dir):\n",
    "    path = [os.path.join(data_dir, f) for f in os.listdir(data_dir)]\n",
    "     \n",
    "    faces = []\n",
    "    ids = []\n",
    "     \n",
    "    for image in path:\n",
    "        img = Image.open(image).convert('L')\n",
    "        imageNp = np.array(img, 'uint8')\n",
    "        id = int(os.path.split(image)[1].split(\".\")[1])\n",
    "         \n",
    "        faces.append(imageNp)\n",
    "        ids.append(id)\n",
    "         \n",
    "    ids = np.array(ids)\n",
    "     \n",
    "    # Train and save classifier\n",
    "    clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    clf.train(faces,ids)\n",
    "    clf.write(\"classifier.xml\")\n",
    "train_classifier(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7be5a75-2742-4f08-9152-6b71a540333c",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     ret, img \u001b[38;5;241m=\u001b[39m video_capture\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 43\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mdraw_boundary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfaceCascade\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofileCascade\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFace\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface Detection\u001b[39m\u001b[38;5;124m\"\u001b[39m, img)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m, in \u001b[0;36mdraw_boundary\u001b[0;34m(img, classifier, profile_classifier, scaleFactor, minNeighbors, color, text, clf)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdraw_boundary\u001b[39m(img, classifier, profile_classifier, scaleFactor, minNeighbors, color, text, clf):\n\u001b[0;32m----> 7\u001b[0m     gray_img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     features \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mdetectMultiScale(gray_img, scaleFactor, minNeighbors)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(features) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    " \n",
    "def draw_boundary(img, classifier, profile_classifier, scaleFactor, minNeighbors, color, text, clf):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    features = classifier.detectMultiScale(gray_img, scaleFactor, minNeighbors)\n",
    "\n",
    "    if len(features) == 0:\n",
    "        features = profile_classifier.detectMultiScale(gray_img, scaleFactor, minNeighbors)\n",
    "        if len(features) == 0:\n",
    "            flipped_gray = cv2.flip(gray_img, 1)\n",
    "            features = profile_classifier.detectMultiScale(flipped_gray, scaleFactor, minNeighbors)\n",
    "     \n",
    "    for (x,y,w,h) in features:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), color, 2 )\n",
    "         \n",
    "        id, pred = clf.predict(gray_img[y:y+h,x:x+w])\n",
    "        confidence = int(100*(1-pred/300))\n",
    "         \n",
    "        if confidence>70:\n",
    "            if id==1:\n",
    "                cv2.putText(img, \"Xuan Phuc\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)\n",
    "            if id==2:\n",
    "                cv2.putText(img, \"Cristiano Ronaldo\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.putText(img, \"UNKNOWN\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 1, cv2.LINE_AA)\n",
    "     \n",
    "    return img\n",
    " \n",
    "# loading classifier\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "profileCascade = cv2.CascadeClassifier(\"haarcascade_profileface.xml\")\n",
    "\n",
    "clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "clf.read(\"classifier.xml\")\n",
    " \n",
    "video_capture = cv2.VideoCapture(0)\n",
    " \n",
    "while True:\n",
    "    ret, img = video_capture.read()\n",
    "    img = draw_boundary(img, faceCascade, profileCascade, 1.4, 6, (0, 255, 0), \"Face\", clf)\n",
    "    cv2.imshow(\"face Detection\", img)\n",
    "     \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
